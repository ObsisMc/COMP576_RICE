{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af16dc28",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-30T04:54:05.666825Z",
     "iopub.status.busy": "2023-10-30T04:54:05.665442Z",
     "iopub.status.idle": "2023-10-30T04:54:12.972869Z",
     "shell.execute_reply": "2023-10-30T04:54:12.971656Z"
    },
    "papermill": {
     "duration": 7.318798,
     "end_time": "2023-10-30T04:54:12.975873",
     "exception": false,
     "start_time": "2023-10-30T04:54:05.657075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "import tqdm\n",
    "from warnings import simplefilter\n",
    "from typing import List\n",
    "import joblib\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717817d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T04:54:12.992377Z",
     "iopub.status.busy": "2023-10-30T04:54:12.990868Z",
     "iopub.status.idle": "2023-10-30T04:54:12.999951Z",
     "shell.execute_reply": "2023-10-30T04:54:12.999091Z"
    },
    "papermill": {
     "duration": 0.018524,
     "end_time": "2023-10-30T04:54:13.002327",
     "exception": false,
     "start_time": "2023-10-30T04:54:12.983803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.system('mkdir lgb-models-optv2')\n",
    "is_train = True\n",
    "is_infer = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d3d65f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T04:54:13.016321Z",
     "iopub.status.busy": "2023-10-30T04:54:13.015558Z",
     "iopub.status.idle": "2023-10-30T04:54:34.460686Z",
     "shell.execute_reply": "2023-10-30T04:54:34.459739Z"
    },
    "papermill": {
     "duration": 21.455183,
     "end_time": "2023-10-30T04:54:34.463454",
     "exception": false,
     "start_time": "2023-10-30T04:54:13.008271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d278ca57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T04:54:34.478123Z",
     "iopub.status.busy": "2023-10-30T04:54:34.477389Z",
     "iopub.status.idle": "2023-10-30T04:56:23.805513Z",
     "shell.execute_reply": "2023-10-30T04:56:23.804079Z"
    },
    "papermill": {
     "duration": 109.338883,
     "end_time": "2023-10-30T04:56:23.808570",
     "exception": false,
     "start_time": "2023-10-30T04:54:34.469687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#整体特征\n",
    "median_sizes = train.groupby('stock_id')['bid_size'].median() + train.groupby('stock_id')['ask_size'].median()\n",
    "std_sizes = train.groupby('stock_id')['bid_size'].std() + train.groupby('stock_id')['ask_size'].std()\n",
    "max_sizes = train.groupby('stock_id')['bid_size'].max() + train.groupby('stock_id')['ask_size'].max()\n",
    "min_sizes = train.groupby('stock_id')['bid_size'].min() + train.groupby('stock_id')['ask_size'].min()\n",
    "mean_sizes = train.groupby('stock_id')['bid_size'].mean() + train.groupby('stock_id')['ask_size'].mean()\n",
    "first_sizes = train.groupby('stock_id')['bid_size'].first() + train.groupby('stock_id')['ask_size'].first()\n",
    "last_sizes = train.groupby('stock_id')['bid_size'].last() + train.groupby('stock_id')['ask_size'].last()\n",
    "#可以再做日期的（好像没看到drop掉日期列）\n",
    "\n",
    "train = train.dropna(subset=['target'])\n",
    "\n",
    "def feature_eng(df):\n",
    "    cols = [c for c in df.columns if c not in ['row_id', 'date_id','time_id']]\n",
    "    df = df[cols]\n",
    "    \n",
    "    #匹配失败数量和匹配成功数量的比率\n",
    "    df['imbalance_ratio'] = df['imbalance_size'] / df['matched_size']\n",
    "    #供需市场的差额\n",
    "    df['bid_ask_volume_diff'] = df['ask_size'] - df['bid_size']\n",
    "    #供需市场总和\n",
    "    df['bid_plus_ask_sizes'] = df['bid_size'] + df['ask_size']\n",
    "    \n",
    "    #供需价格的均值\n",
    "    df['mid_price'] = (df['ask_price'] + df['bid_price']) / 2\n",
    "    \n",
    "    #整体数据情况\n",
    "    df['median_size'] = df['stock_id'].map(median_sizes.to_dict())\n",
    "    df['std_size'] = df['stock_id'].map(std_sizes.to_dict())\n",
    "    df['max_size'] = df['stock_id'].map(max_sizes.to_dict())\n",
    "    df['min_size'] = df['stock_id'].map(min_sizes.to_dict())\n",
    "    df['mean_size'] = df['stock_id'].map(mean_sizes.to_dict())\n",
    "    df['first_size'] = df['stock_id'].map(first_sizes.to_dict())    \n",
    "    df['last_size'] = df['stock_id'].map(last_sizes.to_dict())       \n",
    "    \n",
    "    #整体市场规模和当前的市场规模比较\n",
    "    df['high_volume'] = np.where(df['bid_plus_ask_sizes'] > df['median_size'], 1, 0)\n",
    "    \n",
    "    prices = ['reference_price', 'far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "    \n",
    "    #价格之间做差，做差/求和\n",
    "    for c in combinations(prices, 2):\n",
    "        df[f'{c[0]}_minus_{c[1]}'] = (df[f'{c[0]}'] - df[f'{c[1]}']).astype(np.float32)\n",
    "        df[f'{c[0]}_{c[1]}_imb'] = df.eval(f'({c[0]} - {c[1]})/({c[0]} + {c[1]})')\n",
    "        \n",
    "    for c in combinations(prices, 3):\n",
    "        max_ = df[list(c)].max(axis=1)\n",
    "        min_ = df[list(c)].min(axis=1)\n",
    "        mid_ = df[list(c)].sum(axis=1) - min_ - max_\n",
    "        \n",
    "        df[f'{c[0]}_{c[1]}_{c[2]}_imb2'] = (max_-mid_)/(mid_-min_ + 1e-5)\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return df\n",
    "\n",
    "y = train['target'].values\n",
    "X = feature_eng(train.drop(columns='target'))\n",
    "\n",
    "y_min = np.min(y)\n",
    "y_max = np.max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a103e2da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T04:56:23.822006Z",
     "iopub.status.busy": "2023-10-30T04:56:23.821595Z",
     "iopub.status.idle": "2023-10-30T04:56:23.859025Z",
     "shell.execute_reply": "2023-10-30T04:56:23.857538Z"
    },
    "papermill": {
     "duration": 0.047238,
     "end_time": "2023-10-30T04:56:23.861810",
     "exception": false,
     "start_time": "2023-10-30T04:56:23.814572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "123.91200472226309\n"
     ]
    }
   ],
   "source": [
    "col_num = \"imbalance_ratio\"\n",
    "print(np.isinf(X[col_num]).any())\n",
    "print(X[col_num].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfe22599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T04:56:23.875447Z",
     "iopub.status.busy": "2023-10-30T04:56:23.875062Z",
     "iopub.status.idle": "2023-10-30T04:56:23.880116Z",
     "shell.execute_reply": "2023-10-30T04:56:23.878846Z"
    },
    "papermill": {
     "duration": 0.014632,
     "end_time": "2023-10-30T04:56:23.882422",
     "exception": false,
     "start_time": "2023-10-30T04:56:23.867790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(X.dtypes[X.dtypes == \"int64\" ])\n",
    "# print()\n",
    "# list(X.dtypes[X.dtypes == \"int64\" ].to_dict().keys())\n",
    "# X[(X[\"seconds_in_bucket\"] > 360) & (X[\"seconds_in_bucket\"] < 420)]\n",
    "# X[\"stage\"] = np.where(X[\"seconds_in_bucket\"] > 300, 1, 0)\n",
    "# X.dtypes\n",
    "# X = X.drop(columns=[\"stage\"])\n",
    "# X.isna().any().any()\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e39012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T04:56:23.895942Z",
     "iopub.status.busy": "2023-10-30T04:56:23.895546Z",
     "iopub.status.idle": "2023-10-30T04:56:28.453850Z",
     "shell.execute_reply": "2023-10-30T04:56:28.452645Z"
    },
    "papermill": {
     "duration": 4.568377,
     "end_time": "2023-10-30T04:56:28.456712",
     "exception": false,
     "start_time": "2023-10-30T04:56:23.888335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imbalance_size                         float64\n",
      "reference_price                        float64\n",
      "matched_size                           float64\n",
      "far_price                              float64\n",
      "near_price                             float64\n",
      "                                        ...   \n",
      "far_price_bid_price_wap_imb2           float64\n",
      "near_price_ask_price_bid_price_imb2    float64\n",
      "near_price_ask_price_wap_imb2          float64\n",
      "near_price_bid_price_wap_imb2          float64\n",
      "ask_price_bid_price_wap_imb2           float64\n",
      "Length: 71, dtype: object\n",
      "\n",
      "stock_id                   int64\n",
      "imbalance_buy_sell_flag    int64\n",
      "high_volume                int64\n",
      "stage                      int64\n",
      "min_in_bucket              int64\n",
      "dtype: object\n",
      "   stock_id  imbalance_buy_sell_flag  high_volume  stage  min_in_bucket\n",
      "0         0                        2            1      0              0\n",
      "1         1                        0            0      0              0\n",
      "2         2                        0            1      0              0\n",
      "3         3                        0            1      0              0\n",
      "4         4                        0            0      0              0\n",
      "stock_id                   0\n",
      "imbalance_buy_sell_flag    0\n",
      "high_volume                0\n",
      "stage                      0\n",
      "min_in_bucket              0\n",
      "dtype: int64\n",
      "stock_id                   200\n",
      "imbalance_buy_sell_flag      3\n",
      "high_volume                  2\n",
      "stage                        2\n",
      "min_in_bucket                9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def feat_eng_nn(df: pd.DataFrame):\n",
    "    # change seconds_in_bucket to 9 categories (9 min) & make a new col\n",
    "    df[\"stage\"] = np.where(df[\"seconds_in_bucket\"] > 300, 1, 0)\n",
    "    df[\"min_in_bucket\"] = df[\"seconds_in_bucket\"]\n",
    "    for i in range(9):\n",
    "        t1, t2 = i * 60, ((i+1) * 60 if i < 8 else 541 )\n",
    "        df.loc[(df[\"min_in_bucket\"] >= t1) & (df[\"min_in_bucket\"] < t2), \"min_in_bucket\"] = i \n",
    "\n",
    "    # create discrete feature\n",
    "    int_feat = df.dtypes[df.dtypes == \"int64\"].to_dict().keys()\n",
    "    \n",
    "    # handle invaild values\n",
    "    X_dsc = df[int_feat]\n",
    "    for f in int_feat:\n",
    "        mv = np.min(X_dsc[f])\n",
    "        if mv < 0:\n",
    "            X_dsc[f] += 0 - mv\n",
    "    X_dsc = X_dsc.drop(columns=\"seconds_in_bucket\")\n",
    "    assert not X_dsc.isnull().any().any()\n",
    "    cat_num = X_dsc.nunique()\n",
    "    \n",
    "    X_ctg = df.drop(columns=int_feat)\n",
    "    X_ctg = X_ctg.fillna(0)\n",
    "    \n",
    "    \n",
    "    return X_ctg, X_dsc, cat_num\n",
    "\n",
    "X_ctg, X_dsc, cat_num = feat_eng_nn(X)\n",
    "print(X_ctg.dtypes)\n",
    "print()\n",
    "print(X_dsc.dtypes)\n",
    "print(X_dsc.head())\n",
    "print(X_dsc.min())\n",
    "print(cat_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37d8a841",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T04:56:28.470762Z",
     "iopub.status.busy": "2023-10-30T04:56:28.470290Z",
     "iopub.status.idle": "2023-10-30T04:56:29.723750Z",
     "shell.execute_reply": "2023-10-30T04:56:29.722416Z"
    },
    "papermill": {
     "duration": 1.263386,
     "end_time": "2023-10-30T04:56:29.726253",
     "exception": false,
     "start_time": "2023-10-30T04:56:28.462867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "imbalance_size                         2.982028e+09\n",
      "reference_price                        1.077488e+00\n",
      "matched_size                           7.713682e+09\n",
      "far_price                              4.379531e+02\n",
      "near_price                             1.309732e+00\n",
      "                                           ...     \n",
      "far_price_bid_price_wap_imb2           4.122233e+06\n",
      "near_price_ask_price_bid_price_imb2    1.618361e+03\n",
      "near_price_ask_price_wap_imb2          1.073859e+04\n",
      "near_price_bid_price_wap_imb2          1.004060e+04\n",
      "ask_price_bid_price_wap_imb2           5.029375e+02\n",
      "Length: 71, dtype: float64\n",
      "4122232.867510628\n"
     ]
    }
   ],
   "source": [
    "print(np.isinf(X_ctg).any().any())\n",
    "print(X_ctg.max())\n",
    "# X_ctg[\"far_price_bid_price_wap_imb2\"].replace(np.inf, 0)\n",
    "print(np.max(X_ctg[\"far_price_bid_price_wap_imb2\"].replace(np.inf, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48e5364f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T04:56:29.741164Z",
     "iopub.status.busy": "2023-10-30T04:56:29.740754Z",
     "iopub.status.idle": "2023-10-30T04:56:29.751567Z",
     "shell.execute_reply": "2023-10-30T04:56:29.748888Z"
    },
    "papermill": {
     "duration": 0.021586,
     "end_time": "2023-10-30T04:56:29.754542",
     "exception": false,
     "start_time": "2023-10-30T04:56:29.732956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NNDataset(Dataset):\n",
    "    def __init__(self, X_c, X_d, y_nn):\n",
    "        self.X_c = X_c\n",
    "        self.X_d = X_d\n",
    "        self.y_nn = y_nn\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_d)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.y_nn is None:\n",
    "            return torch.tensor(self.X_c.iloc[idx]).float(), torch.tensor(self.X_d.iloc[idx]).long()\n",
    "        return torch.tensor(self.X_c.iloc[idx]).float(), torch.tensor(self.X_d.iloc[idx]).long(), torch.tensor(self.y_nn[idx]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acc4861e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T04:56:29.768939Z",
     "iopub.status.busy": "2023-10-30T04:56:29.768486Z",
     "iopub.status.idle": "2023-10-30T04:56:29.783410Z",
     "shell.execute_reply": "2023-10-30T04:56:29.781859Z"
    },
    "papermill": {
     "duration": 0.025079,
     "end_time": "2023-10-30T04:56:29.786005",
     "exception": false,
     "start_time": "2023-10-30T04:56:29.760926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 src_num_dim: int,\n",
    "                 n_categories: List[int],\n",
    "                 dropout: float = 0.0,\n",
    "                 hidden: int = 50,\n",
    "                 emb_dim: int = 10,\n",
    "                 dropout_cat: float = 0,\n",
    "                 bn: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embs = nn.ModuleList([\n",
    "            nn.Embedding(x, emb_dim) for x in n_categories])\n",
    "        self.cat_dim = emb_dim * len(n_categories)\n",
    "        self.dropout_cat = nn.Dropout(dropout_cat)\n",
    "        \n",
    "        for emb in self.embs:\n",
    "            nn.init.xavier_normal_(emb.weight)\n",
    "\n",
    "        if bn:\n",
    "            self.sequence = nn.Sequential(\n",
    "                nn.Linear(src_num_dim + self.cat_dim, hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.BatchNorm1d(hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.BatchNorm1d(hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, 1)\n",
    "            )\n",
    "        else:\n",
    "            self.sequence = nn.Sequential(\n",
    "                nn.Linear(src_num_dim + self.cat_dim, hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, 1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        embs = [embedding(x_cat[:, i]) for i, embedding in enumerate(self.embs)]\n",
    "        x_cat_emb = self.dropout_cat(torch.cat(embs, 1))\n",
    "        x_all = torch.cat([x_num, x_cat_emb], 1)\n",
    "        x = self.sequence(x_all)\n",
    "        return torch.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e780f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T04:56:29.800076Z",
     "iopub.status.busy": "2023-10-30T04:56:29.799689Z",
     "iopub.status.idle": "2023-10-30T04:56:29.805654Z",
     "shell.execute_reply": "2023-10-30T04:56:29.804482Z"
    },
    "papermill": {
     "duration": 0.016338,
     "end_time": "2023-10-30T04:56:29.808535",
     "exception": false,
     "start_time": "2023-10-30T04:56:29.792197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5237892, 77)\n",
      "(5237892,)\n",
      "There are 5237892 training data\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(\"There are 5237892 training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "504da652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T04:56:29.823065Z",
     "iopub.status.busy": "2023-10-30T04:56:29.822649Z",
     "iopub.status.idle": "2023-10-30T04:56:29.855618Z",
     "shell.execute_reply": "2023-10-30T04:56:29.854241Z"
    },
    "papermill": {
     "duration": 0.043411,
     "end_time": "2023-10-30T04:56:29.858321",
     "exception": false,
     "start_time": "2023-10-30T04:56:29.814910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5237892 71\n"
     ]
    }
   ],
   "source": [
    "N_Folds = 4\n",
    "kf = KFold(n_splits=N_Folds, shuffle=True, random_state=2023)\n",
    "is_train = True\n",
    "params_nn = {\n",
    "    \"batch_size\": 512,\n",
    "    \"lr\": 1e-3,\n",
    "    \"epochs\": 25,\n",
    "    \"val_iter\": 3000,\n",
    "    \"train_log_step\": 500,\n",
    "    \"scheduler_factor\":0.25,\n",
    "    \"scd_patience\": 2,\n",
    "    \"patience\": 3\n",
    "}\n",
    "\n",
    "N, D_c = X_ctg.shape\n",
    "print(N, D_c)\n",
    "embed_dims = list(cat_num.to_dict().values())\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "output_dir = \"mlp_models\"\n",
    "os.system(f'mkdir {output_dir}')\n",
    "if is_train:\n",
    "    for fold_i, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
    "        if fold_i == 0: continue\n",
    "        # data\n",
    "        tr_X_ctg, tr_X_dsc, tr_y = X_ctg.iloc[train_idx], X_dsc.iloc[train_idx], y[train_idx]\n",
    "        valid_idx_small = valid_idx[:600000]\n",
    "        val_X_ctg, val_X_dsc, val_y = X_ctg.iloc[valid_idx_small], X_dsc.iloc[valid_idx_small], y[valid_idx_small]\n",
    "        \n",
    "        # build torch dataset and dataloader \n",
    "        dataset_tr = NNDataset(tr_X_ctg, tr_X_dsc, tr_y)\n",
    "        dataset_val = NNDataset(val_X_ctg, val_X_dsc, val_y)\n",
    "        \n",
    "        loader_tr = DataLoader(dataset_tr, batch_size=params_nn[\"batch_size\"], shuffle=True, num_workers=4)\n",
    "        loader_val = DataLoader(dataset_val, batch_size=params_nn[\"batch_size\"], shuffle=False, num_workers=4)\n",
    "        \n",
    "        # build model and related modules\n",
    "        model = MLP(D_c,embed_dims,dropout=0.1,hidden=512,emb_dim=32,dropout_cat=0,bn=True)\n",
    "        model.to(device)\n",
    "        criterion = nn.L1Loss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params_nn[\"lr\"])\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", \n",
    "                                                         factor=params_nn[\"scheduler_factor\"],\n",
    "                                                         patience=params_nn[\"scd_patience\"])\n",
    "        \n",
    "        # begin training\n",
    "        n_iter = np.ceil(len(dataset_tr) / params_nn[\"batch_size\"])\n",
    "        best_loss = np.inf\n",
    "        last_epoch_loss = np.inf\n",
    "        p = 0\n",
    "        for epoch in range(params_nn[\"epochs\"]):\n",
    "            loss_epoch = []\n",
    "            for i, (x_c, x_d, y_tr) in enumerate(loader_tr):\n",
    "                optimizer.zero_grad()\n",
    "                x_c, x_d, y_tr = x_c.to(device), x_d.to(device), y_tr.to(device)\n",
    "                y_hat = model(x_c, x_d)\n",
    "                loss = criterion(y_hat, y_tr)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                loss_epoch.append(loss.detach().item())\n",
    "                \n",
    "                # log\n",
    "                if i != 0 and i % params_nn[\"train_log_step\"] == 0:\n",
    "                    print(f\"Fold {fold_i:1}, \"\n",
    "                          f\"Epoch {epoch:2}/{params_nn['epochs']:2}, \"\n",
    "                          f\"iter {i:5}/{n_iter:5}, \"\n",
    "                          f\"loss {np.mean(loss_epoch[-params_nn['train_log_step']:]):8.4f}\")\n",
    "                \n",
    "                # validate\n",
    "                if i % params_nn[\"val_iter\"] == 0 and i != 0 or i == n_iter - 1:\n",
    "                    loss_val = []\n",
    "                    bar = tqdm.tqdm(total=np.ceil(len(dataset_val) / params_nn[\"batch_size\"]))\n",
    "                    with torch.no_grad():\n",
    "                        for i, (x_c, x_d, y_val) in enumerate(loader_val):\n",
    "                            x_c, x_d, y_val = x_c.to(device), x_d.to(device), y_val.to(device)\n",
    "\n",
    "                            y_hat = model(x_c, x_d)\n",
    "                            loss = criterion(y_hat, y_val)\n",
    "\n",
    "                            loss_val.append(loss.item())\n",
    "                            bar.update()\n",
    "                    \n",
    "                    loss_val_avg = np.mean(loss_val)\n",
    "                    print(f\"==> Val current best loss {best_loss:8.4f}\")\n",
    "                    print(f\"Fold {fold_i:1}, \"\n",
    "                          f\"Epoch {epoch:2}/{params_nn['epochs']:2}, \"\n",
    "                          f\"Valid loss {loss_val_avg:8.4f}\")\n",
    "                    if loss_val_avg < best_loss:\n",
    "                        best_loss = loss_val_avg\n",
    "                        print(f\"Loss decreases! current best loss {best_loss:8.4f}\")\n",
    "                        torch.save(model, os.path.join(output_dir, f\"fold{fold_i}.pt\"))\n",
    "                    print()\n",
    "            \n",
    "            # early stop\n",
    "            if loss_val_avg >= last_epoch_loss:\n",
    "                p += 1\n",
    "                print(f\"Best loss doesn't decrease in this epoch, patience {p}/{params_nn['patience']}\")\n",
    "                if p >= params_nn[\"patience\"]:\n",
    "                    print(f\"Reach patience, quit training of fold {fold_i}\")\n",
    "                    print()\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"Epoch loss decreases from {last_epoch_loss:8.4f} to {loss_val_avg:8.4f}\")\n",
    "                last_epoch_loss = loss_val_avg\n",
    "                p = 0\n",
    "            \n",
    "            # scheduler\n",
    "            scheduler.step(loss_val_avg)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5531a0d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T04:56:29.873029Z",
     "iopub.status.busy": "2023-10-30T04:56:29.872600Z",
     "iopub.status.idle": "2023-10-30T04:58:21.110277Z",
     "shell.execute_reply": "2023-10-30T04:58:21.109138Z"
    },
    "papermill": {
     "duration": 111.248332,
     "end_time": "2023-10-30T04:58:21.113246",
     "exception": false,
     "start_time": "2023-10-30T04:56:29.864914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices)/np.sum(std_error)\n",
    "    out = prices-std_error*step\n",
    "    \n",
    "    return out\n",
    "\n",
    "is_infer = False\n",
    "N_Folds = 2\n",
    "if is_infer:\n",
    "    import optiver2023\n",
    "    env = optiver2023.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    counter = 0\n",
    "    predictions = []\n",
    "    \n",
    "    batch_size_test = 128\n",
    "    for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "        feat = feature_eng(test)\n",
    "        X_ctg, X_dsc, cat_num = feat_eng_nn(feat)\n",
    "        test_dataset = NNDataset(X_ctg, X_dsc, None)\n",
    "        test_loader = DataLoader(test_dataset,batch_size=batch_size_test,shuffle=False)\n",
    "        \n",
    "        fold_prediction = np.zeros((test.shape[0],))\n",
    "        for fold in range(0, N_Folds):\n",
    "            model_filename = f\"/kaggle/input/mlp-model2/mlp_models/fold{fold+1}.pt\"\n",
    "            m = torch.load(model_filename)\n",
    "            for data_i, (x_c, x_d) in enumerate(test_loader):\n",
    "                y_hat = m(x_c, x_d)\n",
    "                fold_prediction[data_i * batch_size_test: (data_i + 1) * batch_size_test] += y_hat.detach().cpu().numpy()\n",
    "                \n",
    "        fold_prediction /= N_Folds\n",
    "        fold_prediction = zero_sum(fold_prediction, test.loc[:,'bid_size'] + test.loc[:,'ask_size'])\n",
    "        clipped_predictions = np.clip(fold_prediction, y_min, y_max)\n",
    "        sample_prediction['target'] = clipped_predictions\n",
    "        env.predict(sample_prediction)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2383f57a",
   "metadata": {
    "papermill": {
     "duration": 0.006232,
     "end_time": "2023-10-30T04:58:21.126205",
     "exception": false,
     "start_time": "2023-10-30T04:58:21.119973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 261.673197,
   "end_time": "2023-10-30T04:58:23.540545",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-30T04:54:01.867348",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}