{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26147f20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:27:43.122428Z",
     "iopub.status.busy": "2023-11-18T22:27:43.121479Z",
     "iopub.status.idle": "2023-11-18T22:28:06.253180Z",
     "shell.execute_reply": "2023-11-18T22:28:06.252251Z"
    },
    "papermill": {
     "duration": 23.144484,
     "end_time": "2023-11-18T22:28:06.255922",
     "exception": false,
     "start_time": "2023-11-18T22:27:43.111438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "main_dir = '/kaggle/input/optiver-trading-at-the-close/'\n",
    "#main_dir = ''\n",
    "train = pd.read_csv(main_dir + 'train.csv')\n",
    "train = train.loc[train['target'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3d0a41b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:28:06.272354Z",
     "iopub.status.busy": "2023-11-18T22:28:06.271615Z",
     "iopub.status.idle": "2023-11-18T22:28:06.285941Z",
     "shell.execute_reply": "2023-11-18T22:28:06.284719Z"
    },
    "papermill": {
     "duration": 0.025501,
     "end_time": "2023-11-18T22:28:06.288564",
     "exception": false,
     "start_time": "2023-11-18T22:28:06.263063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 填补空值far_price，near_price，返回三个结果\n",
    "def imputer(df):\n",
    "    far_price_mean = df['far_price'].mean()\n",
    "    near_price_mean = df['near_price'].mean()\n",
    "    df['far_price'] = df['far_price'].fillna(far_price_mean)\n",
    "    df['near_price'] = df['near_price'].fillna(near_price_mean)\n",
    "\n",
    "    return df, far_price_mean, near_price_mean\n",
    "\n",
    "# 补充缺失的行\n",
    "def add_missing_data(df):\n",
    "    all_stock_ids = set(range(200))\n",
    "    all_missed_data_list = []\n",
    "\n",
    "    # 将数据预先进行分组，以便我们可以快速访问每个time_id的相关数据\n",
    "    grouped = df.groupby('time_id')\n",
    "\n",
    "    for t, group in grouped:\n",
    "        current_stock_ids = set(group['stock_id'].to_list())\n",
    "        missed_stock_id = list(all_stock_ids - current_stock_ids)\n",
    "        \n",
    "        date_id = group['date_id'].iloc[-1]\n",
    "        seconds_in_bucket = group['seconds_in_bucket'].iloc[-1]\n",
    "        \n",
    "        missed_stock_id_num = len(missed_stock_id)\n",
    "        missed_date_id = [date_id] * missed_stock_id_num\n",
    "        missed_seconds_in_bucket = [seconds_in_bucket] * missed_stock_id_num\n",
    "        missed_time_id = [t] * missed_stock_id_num\n",
    "        \n",
    "        missed_data = pd.DataFrame({\n",
    "            'stock_id': missed_stock_id,\n",
    "            'date_id': missed_date_id,\n",
    "            'seconds_in_bucket': missed_seconds_in_bucket,\n",
    "            'time_id': missed_time_id\n",
    "        })\n",
    "        \n",
    "        all_missed_data_list.append(missed_data)\n",
    "\n",
    "    all_missed_data = pd.concat(all_missed_data_list, axis=0).reset_index(drop=True).astype(int)\n",
    "\n",
    "    df = pd.concat([df, all_missed_data], axis=0)\n",
    "    df = df.sort_values(by=['time_id', 'stock_id']).reset_index(drop=True)\n",
    "    df = df.groupby('stock_id').apply(lambda x: x.fillna(method='bfill')).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a7c2949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:28:06.305031Z",
     "iopub.status.busy": "2023-11-18T22:28:06.304260Z",
     "iopub.status.idle": "2023-11-18T22:28:34.784861Z",
     "shell.execute_reply": "2023-11-18T22:28:34.783660Z"
    },
    "papermill": {
     "duration": 28.491748,
     "end_time": "2023-11-18T22:28:34.787514",
     "exception": false,
     "start_time": "2023-11-18T22:28:06.295766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "空值数： 0\n"
     ]
    }
   ],
   "source": [
    "train, far_price_mean, near_price_mean = imputer(train)\n",
    "train = add_missing_data(train)\n",
    "print('空值数：', train.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e449e506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:28:34.804434Z",
     "iopub.status.busy": "2023-11-18T22:28:34.803965Z",
     "iopub.status.idle": "2023-11-18T22:28:34.813223Z",
     "shell.execute_reply": "2023-11-18T22:28:34.812001Z"
    },
    "papermill": {
     "duration": 0.021155,
     "end_time": "2023-11-18T22:28:34.815722",
     "exception": false,
     "start_time": "2023-11-18T22:28:34.794567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sizesum_and_pricestd(df):\n",
    "    # 更新后增加10个特征\n",
    "    price_ftrs = ['reference_price', 'far_price', 'near_price', 'bid_price', 'ask_price', 'wap'] # std\n",
    "    size_ftrs = ['imbalance_size', 'matched_size', 'bid_size', 'ask_size'] # sum\n",
    "    \n",
    "    rolled = df[['stock_id'] + size_ftrs].groupby('stock_id').rolling(window=6, min_periods=1).sum()\n",
    "    rolled = rolled.reset_index(level=0, drop=True)\n",
    "    for col in size_ftrs:\n",
    "        df[f'{col}_rolled_sum'] = rolled[col]\n",
    "\n",
    "    rolled = df[['stock_id'] + price_ftrs].groupby('stock_id').rolling(window=6, min_periods=1).std().fillna(0)\n",
    "    rolled = rolled.reset_index(level=0, drop=True)\n",
    "    for col in price_ftrs:\n",
    "        df[f'{col}_rolled_std'] = rolled[col]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19be3a27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:28:34.831800Z",
     "iopub.status.busy": "2023-11-18T22:28:34.831403Z",
     "iopub.status.idle": "2023-11-18T22:28:41.653496Z",
     "shell.execute_reply": "2023-11-18T22:28:41.652218Z"
    },
    "papermill": {
     "duration": 6.833643,
     "end_time": "2023-11-18T22:28:41.656626",
     "exception": false,
     "start_time": "2023-11-18T22:28:34.822983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = sizesum_and_pricestd(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d4ee663",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:28:41.673010Z",
     "iopub.status.busy": "2023-11-18T22:28:41.672630Z",
     "iopub.status.idle": "2023-11-18T22:28:41.679245Z",
     "shell.execute_reply": "2023-11-18T22:28:41.678106Z"
    },
    "papermill": {
     "duration": 0.017708,
     "end_time": "2023-11-18T22:28:41.681719",
     "exception": false,
     "start_time": "2023-11-18T22:28:41.664011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 删除列表元素\n",
    "def remove_element(input_list, drop_list):\n",
    "    return [e for e in input_list if e not in drop_list]\n",
    "\n",
    "no_feature_cols = ['date_id', 'row_id', 'time_id', 'target', 'currently_scored']\n",
    "\n",
    "feature_cols = remove_element(train.columns, no_feature_cols)\n",
    "target_col = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4c678ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:28:41.697992Z",
     "iopub.status.busy": "2023-11-18T22:28:41.697589Z",
     "iopub.status.idle": "2023-11-18T22:28:41.703467Z",
     "shell.execute_reply": "2023-11-18T22:28:41.702245Z"
    },
    "papermill": {
     "duration": 0.017404,
     "end_time": "2023-11-18T22:28:41.706485",
     "exception": false,
     "start_time": "2023-11-18T22:28:41.689081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征数： 23\n"
     ]
    }
   ],
   "source": [
    "print('特征数：', len(feature_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9fc571e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:28:41.723450Z",
     "iopub.status.busy": "2023-11-18T22:28:41.722556Z",
     "iopub.status.idle": "2023-11-18T22:28:45.328104Z",
     "shell.execute_reply": "2023-11-18T22:28:45.326826Z"
    },
    "papermill": {
     "duration": 3.617208,
     "end_time": "2023-11-18T22:28:45.330852",
     "exception": false,
     "start_time": "2023-11-18T22:28:41.713644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 标准化\n",
    "avg = train[feature_cols].mean()\n",
    "std = train[feature_cols].std()\n",
    "\n",
    "train[feature_cols] = (train[feature_cols] - avg)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee5ecd2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:28:45.346786Z",
     "iopub.status.busy": "2023-11-18T22:28:45.346341Z",
     "iopub.status.idle": "2023-11-18T22:29:03.769981Z",
     "shell.execute_reply": "2023-11-18T22:29:03.768906Z"
    },
    "papermill": {
     "duration": 18.43476,
     "end_time": "2023-11-18T22:29:03.772683",
     "exception": false,
     "start_time": "2023-11-18T22:28:45.337923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将数据转为float32数据类型\n",
    "train = train.astype('float32')\n",
    "\n",
    "seq_len = 6\n",
    "\n",
    "# Grouping by time_id\n",
    "grouped_by_time = train.groupby('stock_id')\n",
    "\n",
    "def generate_data(grouped_by_time, seq_len):\n",
    "    for _, group in grouped_by_time:\n",
    "        # Sorting by stock_id to maintain consistency across images\n",
    "        group_sorted = group.sort_values(by='time_id')\n",
    "        \n",
    "        features = group_sorted[feature_cols].values\n",
    "\n",
    "        windows = []\n",
    "\n",
    "        for t in range(0, seq_len - 1):\n",
    "            copy_0 = np.stack([features[0]] * (seq_len - 1 - t))\n",
    "            cut_0 = features[: t + 1]\n",
    "            windows.append(np.vstack((copy_0, cut_0)))\n",
    "            \n",
    "        for t in range(0, features.shape[0] - seq_len + 1):\n",
    "            windows.append(features[t: t+seq_len, :])\n",
    "        \n",
    "        # Convert list of windows to numpy array\n",
    "        features_array = np.stack(windows)\n",
    "        \n",
    "        target = group_sorted['target'].values\n",
    "\n",
    "        # Yield the result for this group to avoid storing all results in memory\n",
    "        yield features_array, target\n",
    "\n",
    "# Use generator to iterate over data\n",
    "data_generator = generate_data(grouped_by_time, seq_len=seq_len)\n",
    "\n",
    "# If you need to store results in arrays:\n",
    "datas, labels = zip(*data_generator)\n",
    "data = np.array(datas).reshape(-1, seq_len, len(feature_cols))\n",
    "label = np.array(labels).reshape(-1,)\n",
    "\n",
    "#del train, datas, labels, grouped_by_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e782fa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:29:03.789326Z",
     "iopub.status.busy": "2023-11-18T22:29:03.788599Z",
     "iopub.status.idle": "2023-11-18T22:29:03.792940Z",
     "shell.execute_reply": "2023-11-18T22:29:03.791743Z"
    },
    "papermill": {
     "duration": 0.015306,
     "end_time": "2023-11-18T22:29:03.795353",
     "exception": false,
     "start_time": "2023-11-18T22:29:03.780047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(feature_cols, len(feature_cols))\n",
    "# print(test_cols, len(test_cols))\n",
    "# print([c for c in test_cols if c not in feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a43e97d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:29:03.811619Z",
     "iopub.status.busy": "2023-11-18T22:29:03.811170Z",
     "iopub.status.idle": "2023-11-18T22:29:09.862514Z",
     "shell.execute_reply": "2023-11-18T22:29:09.861169Z"
    },
    "papermill": {
     "duration": 6.062491,
     "end_time": "2023-11-18T22:29:09.865128",
     "exception": false,
     "start_time": "2023-11-18T22:29:03.802637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检查设备： cpu\n",
      "特征形状 torch.Size([5291000, 6, 23])\n",
      "标签形状 torch.Size([5291000])\n",
      "batch形状： torch.Size([4096, 6, 23])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# 打印设备\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('检查设备：', device)\n",
    "\n",
    "\n",
    "data = torch.tensor(data, dtype=torch.float32).to(device)\n",
    "label = torch.tensor(label, dtype=torch.float32).to(device)\n",
    "\n",
    "print('特征形状', data.shape)\n",
    "print('标签形状', label.shape)\n",
    "\n",
    "# 分开训练集和验证集\n",
    "torch.manual_seed(42)\n",
    "\n",
    "dataset = TensorDataset(data, label)\n",
    "\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "batch_size = 4096\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "\n",
    "print('batch形状：', next(iter(train_loader))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76939690",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:29:09.882155Z",
     "iopub.status.busy": "2023-11-18T22:29:09.881572Z",
     "iopub.status.idle": "2023-11-18T22:29:09.892396Z",
     "shell.execute_reply": "2023-11-18T22:29:09.891082Z"
    },
    "papermill": {
     "duration": 0.022457,
     "end_time": "2023-11-18T22:29:09.895145",
     "exception": false,
     "start_time": "2023-11-18T22:29:09.872688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, feature_num, d_model, nhead, num_layers):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = nn.Linear(feature_num, d_model)\n",
    "        self.tf1 = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.tf2 = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_layers, batch_first=True)\n",
    "        self.decoder = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.tf1.encoder(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.tf2.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a8b7eac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:29:09.912810Z",
     "iopub.status.busy": "2023-11-18T22:29:09.912420Z",
     "iopub.status.idle": "2023-11-18T22:29:09.929862Z",
     "shell.execute_reply": "2023-11-18T22:29:09.928609Z"
    },
    "papermill": {
     "duration": 0.029929,
     "end_time": "2023-11-18T22:29:09.932650",
     "exception": false,
     "start_time": "2023-11-18T22:29:09.902721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_train = True\n",
    "if is_train:\n",
    "    input_size = data.shape[-1]\n",
    "\n",
    "    n_epochs = 50\n",
    "    lr = 1e-03\n",
    "\n",
    "    # pre mae init\n",
    "    pre_epoch_valid_mae = np.inf\n",
    "\n",
    "    # 当前学习率下，mae两轮不下降就就将学习率减半\n",
    "    patience_counter = 0\n",
    "\n",
    "    model = MyModel(feature_num=input_size, d_model=64, nhead=8, num_layers=1).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    loss = nn.L1Loss().to(device)\n",
    "\n",
    "    out_path = \"model/\"\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "    best_mae = np.inf\n",
    "\n",
    "    print(f'Train start...')\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_maes = []\n",
    "        batch_num = len(train_loader)\n",
    "\n",
    "        # 训练\n",
    "        for X, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X).squeeze()\n",
    "            l = loss(outputs, y)\n",
    "            l.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            optimizer.step()\n",
    "            mae = l.item()\n",
    "            train_maes.append(mae)\n",
    "        epoch_train_mae = np.mean(train_maes)\n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}] Training average MAE: {epoch_train_mae:.4f}')\n",
    "        train_maes = []\n",
    "\n",
    "        # 验证\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_maes = []\n",
    "            for X_v, y_v in valid_loader:\n",
    "                preds = model(X_v).squeeze()\n",
    "                mae = torch.abs(preds - y_v).mean().item()\n",
    "                valid_maes.append(mae)\n",
    "            epoch_valid_mae = np.mean(valid_maes)\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}] Validation average MAE: {epoch_valid_mae:.4f}')\n",
    "\n",
    "            if epoch_valid_mae < best_mae:\n",
    "                best_mae = epoch_valid_mae\n",
    "                torch.save(model, os.path.join(out_path, f\"model_epoch_{epoch+1}.pt\"))\n",
    "\n",
    "        # 前一轮mae必须小于当前mae，否则学习率减半\n",
    "        if epoch_valid_mae - pre_epoch_valid_mae > 0:\n",
    "            patience_counter += 1\n",
    "\n",
    "            if patience_counter == 2:\n",
    "                lr = lr * 0.5\n",
    "                patience_counter = 0\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = lr  # 更新学习率\n",
    "                    print(f'renew lr to {lr}')\n",
    "\n",
    "        # 更新mae\n",
    "        pre_epoch_valid_mae = epoch_valid_mae\n",
    "\n",
    "        # 劈叉超过0.03或者学习率低于1e-7，停止训练\n",
    "        if (epoch_valid_mae - epoch_train_mae > 0.03) or (lr <1e-7):\n",
    "            print('Early stop now.')\n",
    "            break\n",
    "\n",
    "    print(f'Train over.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f34b3ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:29:09.950390Z",
     "iopub.status.busy": "2023-11-18T22:29:09.949970Z",
     "iopub.status.idle": "2023-11-18T22:29:09.964254Z",
     "shell.execute_reply": "2023-11-18T22:29:09.962905Z"
    },
    "papermill": {
     "duration": 0.02589,
     "end_time": "2023-11-18T22:29:09.966590",
     "exception": false,
     "start_time": "2023-11-18T22:29:09.940700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestStack:\n",
    "    # 添加time_id\n",
    "    def __init__(self, window_size=6):\n",
    "        self.window_size = window_size * 2\n",
    "        self.stock_cache = []  # Dictionary to hold cache for each stock\n",
    "\n",
    "    def test_stack(self, test, time_id):\n",
    "        # Convert batch_data to DataFrame if it's a list of dicts\n",
    "        if isinstance(test, list):\n",
    "            test = pd.DataFrame(test)\n",
    "            \n",
    "        test['time_id'] = time_id\n",
    "        \n",
    "        # 单条数据添加\n",
    "        self.stock_cache.append(test)\n",
    "        \n",
    "        if len(self.stock_cache) > self.window_size:\n",
    "            # 如果当前数据超过n条，就截取最后n条，把之前的丢掉\n",
    "            self.stock_cache = self.stock_cache[-self.window_size:]\n",
    "            test = pd.concat(self.stock_cache, axis=0).reset_index(drop=True)\n",
    "        else:\n",
    "            # 初始化，如果还有收集到n条数据，就把当前的数据复制6次\n",
    "            self.stock_cache = []\n",
    "            for t in range(self.window_size): # [0, 1, 2, 3, 4, 5]\n",
    "                test['time_id'] = t - self.window_size + 1 # [-5, -4, -3, -2, -1, 0]\n",
    "                test_add = test.copy()\n",
    "                self.stock_cache.append(test_add)\n",
    "            test = pd.concat(self.stock_cache, axis=0).reset_index(drop=True).sort_values(by='time_id')\n",
    "            \n",
    "        return test.sort_values(['time_id', 'stock_id'])\n",
    "\n",
    "test_cols = None\n",
    "def df_to_seq(test, seq_len):\n",
    "    grouped_by_stock = test.groupby('stock_id')\n",
    "    datas = []\n",
    "\n",
    "    for _, group in grouped_by_stock:\n",
    "        group_sorted = group.sort_values(by='time_id')\n",
    "        cols = remove_element(test.columns, no_feature_cols)\n",
    "        \n",
    "        features = group_sorted[cols].values # [12, 23]\n",
    "        \n",
    "        features = features[-seq_len:, ]\n",
    "        datas.append(features)\n",
    "\n",
    "    return np.stack(datas)\n",
    "\n",
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices)/np.sum(std_error)\n",
    "    out = prices-std_error*step\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6ad5732",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:29:09.983354Z",
     "iopub.status.busy": "2023-11-18T22:29:09.982939Z",
     "iopub.status.idle": "2023-11-18T22:29:11.088314Z",
     "shell.execute_reply": "2023-11-18T22:29:11.086958Z"
    },
    "papermill": {
     "duration": 1.117642,
     "end_time": "2023-11-18T22:29:11.091726",
     "exception": false,
     "start_time": "2023-11-18T22:29:09.974084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_infer = False\n",
    "if is_infer:\n",
    "    model_idx = [38, 39, 40, 41, 46]\n",
    "    models = []\n",
    "    for midx in model_idx:\n",
    "        models.append(torch.load(f\"/kaggle/input/transformers/model_epoch_{midx}.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbee5db2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:29:11.110300Z",
     "iopub.status.busy": "2023-11-18T22:29:11.108805Z",
     "iopub.status.idle": "2023-11-18T22:29:11.122365Z",
     "shell.execute_reply": "2023-11-18T22:29:11.121077Z"
    },
    "papermill": {
     "duration": 0.026538,
     "end_time": "2023-11-18T22:29:11.125745",
     "exception": false,
     "start_time": "2023-11-18T22:29:11.099207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_pre_test = False\n",
    "if is_pre_test:\n",
    "    # 提交前测试\n",
    "    test_df = pd.read_csv(main_dir + 'example_test_files/test.csv')\n",
    "    #test_df = test_df.drop(columns=['target'])\n",
    "    test_group = test_df.groupby(['time_id'])\n",
    "    tdp = TestStack(window_size=seq_len)\n",
    "\n",
    "    counter = 0\n",
    "    for test in test_group:\n",
    "        test = test[1]\n",
    "        test = test.drop(columns=['time_id'])\n",
    "\n",
    "        # zerosum准备\n",
    "        volumes = test.loc[:,'bid_size'] + test.loc[:,'ask_size']\n",
    "\n",
    "        # 填补空值\n",
    "        test['far_price'] = test['far_price'].fillna(far_price_mean)\n",
    "        test['near_price'] = test['near_price'].fillna(near_price_mean)\n",
    "\n",
    "        # 数据叠加\n",
    "        test_stack = tdp.test_stack(test, counter)\n",
    "\n",
    "        # 特征工程\n",
    "        test = sizesum_and_pricestd(test_stack)\n",
    "\n",
    "        # 标准化\n",
    "        test_cols = remove_element(test.columns, no_feature_cols)\n",
    "        test[test_cols] = (test[test_cols] - avg)/std\n",
    "\n",
    "        # 序列化\n",
    "        test = df_to_seq(test, seq_len)\n",
    "    #     print(test.shape)\n",
    "\n",
    "        # 推理\n",
    "        predictions = np.zeros((test.shape[0],))\n",
    "        for model in models:\n",
    "            test = torch.tensor(test, dtype=torch.float32).squeeze().to(device)\n",
    "            predictions_tmp = model(test).squeeze().cpu()\n",
    "            predictions_tmp = predictions_tmp.detach().numpy()\n",
    "            predictions += predictions_tmp\n",
    "        \n",
    "        predictions /= len(models)\n",
    "        # zero sum调整\n",
    "        predictions = zero_sum(predictions, volumes)\n",
    "\n",
    "        # print(predictions)\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7637756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-18T22:29:11.142902Z",
     "iopub.status.busy": "2023-11-18T22:29:11.142508Z",
     "iopub.status.idle": "2023-11-18T22:29:12.057143Z",
     "shell.execute_reply": "2023-11-18T22:29:12.055979Z"
    },
    "papermill": {
     "duration": 0.926527,
     "end_time": "2023-11-18T22:29:12.060053",
     "exception": false,
     "start_time": "2023-11-18T22:29:11.133526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "import optiver2023\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()\n",
    "tdp = TestStack(window_size=seq_len)\n",
    "\n",
    "counter = 0\n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    \n",
    "    if test.currently_scored.iloc[0]== False:\n",
    "            sample_prediction['target'] = 0\n",
    "            env.predict(sample_prediction)\n",
    "            counter += 1\n",
    "            continue\n",
    "            \n",
    "    # zerosum准备\n",
    "    volumes = test.loc[:,'bid_size'] + test.loc[:,'ask_size']\n",
    "    \n",
    "    # 填补空值\n",
    "    test['far_price'] = test['far_price'].fillna(far_price_mean)\n",
    "    test['near_price'] = test['near_price'].fillna(near_price_mean)\n",
    "        \n",
    "    # 数据叠加\n",
    "    test_stack = tdp.test_stack(test, counter)\n",
    "\n",
    "    # 特征工程\n",
    "    test = sizesum_and_pricestd(test_stack)\n",
    "\n",
    "    # 标准化\n",
    "    test_cols = remove_element(test.columns, no_feature_cols)\n",
    "    test[test_cols] = (test[test_cols] - avg)/std\n",
    "\n",
    "    # 序列化\n",
    "    test = df_to_seq(test, seq_len)\n",
    "\n",
    "    # 推理\n",
    "    predictions = np.zeros((test.shape[0],))\n",
    "    for model in models:\n",
    "        test = torch.tensor(test, dtype=torch.float32).squeeze().to(device)\n",
    "        predictions_tmp = model(test).squeeze().cpu()\n",
    "        predictions_tmp = predictions_tmp.detach().numpy()\n",
    "        predictions += predictions_tmp\n",
    "    predictions /= len(models)\n",
    "\n",
    "    # zero sum调整\n",
    "    predictions = zero_sum(predictions, volumes)\n",
    "    \n",
    "    #print(predictions)\n",
    "\n",
    "    # tensor转换为numpy，给结果赋值\n",
    "    sample_prediction['target'] = predictions.values\n",
    "    \n",
    "    # 提交结果\n",
    "    env.predict(sample_prediction)\n",
    "    \n",
    "    # 计数\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7056235,
     "sourceId": 57891,
     "sourceType": "competition"
    },
    {
     "datasetId": 4009156,
     "sourceId": 6976888,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 94.757439,
   "end_time": "2023-11-18T22:29:13.492926",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-18T22:27:38.735487",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}